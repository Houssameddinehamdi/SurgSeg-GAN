# Ultralytics YOLO ðŸš€, AGPL-3.0 license
# YOLO11-seg instance segmentation model. For Usage examples see https://docs.ultralytics.com/tasks/segment

# Parameters
nc: 12  # number of classes
scales:  # model compound scaling constants, i.e. 'model=yolo11m-seg.yaml' will call yolo11-seg.yaml with scale 'm'
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024]  # summary: 355 layers, 2876848 parameters, 2876832 gradients, 10.5 GFLOPs
  s: [0.50, 0.50, 1024]  # summary: 355 layers, 10113248 parameters, 10113232 gradients, 35.8 GFLOPs
  m: [0.75, 1.00, 512]  # summary: 445 layers, 22420896 parameters, 22420880 gradients, 123.9 GFLOPs
  l: [1.00, 1.00, 512]  # summary: 667 layers, 27678368 parameters, 27678352 gradients, 143.0 GFLOPs
  x: [1.00, 1.50, 512]  # summary: 667 layers, 62142656 parameters, 62142640 gradients, 320.2 GFLOPs


# YOLO11n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C3k2, [256, False, 0.5]]
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 3, C3k2, [512, False, 0.5]]
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 3, C3k2, [512, True, 0.5]]
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C3k2, [1024, True, 0.5]]
  - [-1, 1, SPPF, [1024, 5]]  # 9
  - [-1, 2, C2PSA, [1024]]  # 10

# YOLO11n head
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C3k2, [512, False]]

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C3k2, [256, False]]  # 16 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 13], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C3k2, [512, False]]  # 19 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C3k2, [1024, True]]  # 22 (P5/32-large)

  - [[16, 19, 22], 1, Segment, [nc, 32, 256]]  # Detect(P3, P4, P5)

occlusion_mask_generator:
  type: CNN
  parameters:
    input_channels: 3
    output_channels: 1
    layers:
      - type: ConvLayer
        filters: 64
        kernel_size: 3
        stride: 1
        padding: same
        normalization: GroupNorm
        activation: ReLU
      - type: DepthwiseSeparableConvLayer
        filters: 128
        kernel_size: 3
        stride: 2
        padding: same
        normalization: BatchNorm
        activation: ReLU
      - type: ConvLayer
        filters: 128
        kernel_size: 3
        stride: 1
        padding: same
        normalization: GroupNorm
        activation: ReLU
      - type: FinalLayer
        activation: sigmoid

occlusion_aware_generator:
  type: GAN
  parameters:
    input_channels: 4
    output_channels: 3
    generator_layers:
      - type: ConvLayer
        filters: 64
        kernel_size: 7
        stride: 1
        padding: same
        normalization: GroupNorm
        activation: ReLU
      - type: ResBlock
        filters: 128
        normalization: GroupNorm
        attention: True
      - type: ResBlock
        filters: 128
        normalization: GroupNorm
        attention: True
      - type: FinalLayer
        activation: tanh
    training_optimizations:
      loss: HingeGANLoss
      lr_schedule: CosineAnnealing
      generator_lr: 0.0002
      discriminator_lr: 0.0001

discriminators:
  type: MultiScaleDiscriminator
  parameters:
    num_discriminators: 3
    discriminator_layers:
      - type: ConvLayer
        filters: 64
        kernel_size: 4
        stride: 2
        normalization: SpectralNorm
        activation: LeakyReLU
      - type: ConvLayer
        filters: 128
        kernel_size: 4
        stride: 2
        normalization: SpectralNorm
        activation: LeakyReLU
      - type: FinalLayer
        activation: sigmoid
    shared_features: True
    training_optimizations:
      gradient_penalty: True
      lr_schedule: ExponentialDecay
      discriminator_learning_rate: 0.0001
      gradient_penalty_weight: 10

# Dynamic Training Settings (To be implemented in your training script)
dynamic_training:
    learning_rate_scheduler:
        patience: 5 # For LR Decay
        reduce_factor: 0.5 # For LR Decay
        threshold: 0.05 # Loss threshold
    augmentation_scheduler:
        augmentation_step_size: 0.2
        reduce_factor: 0.5
    early_stopping:
        patience: 10 # For Early Stopping
    # Initial values for dynamic variables should be set in the script
    # Example: initial_learning_rate, initial_augmentation_level

# Settings for handling underrepresented classes (To be implemented in your training script)
underrepresented_classes:
  mode: "filter"  # Options: "filter", "weight", "augment", or "hybrid"
  classes_to_ignore:  # List of classes to ignore or treat specially, depending on the `mode`.
    - "Background"
  class_weights: # If mode is "weight", you can specify the class weights. This will be implemented in the training script.
    #   "class_name1": 1.0
    #   "class_name2": 0.5
    #   "class_name3": 0.2

    #If mode is augment, you can provide values to customize the data augmentations.

  augmentation:
      type: "copy_paste" # Type of augmentation (e.g., copy-paste, stronger geometric transforms).
      strength: 0.75 # Augmentation Strength.

# Placeholder to indicate where the dynamic adjustments and class handling will be applied
# NOTE: You must implement these adjustments in your custom training code.
# Use this section as a guideline for how to control dynamic behavior

# For Example

# Inside your training loop:
#
#   1.  Monitor Validation Performance (loss, mAP, etc.).
#
#   2. Implement the  `adjust_learning_rate` , `adjust_augmentation`, and `check_early_stopping` functions.
#
#       * This  `adjust_learning_rate` should be called inside the validation loop and should be used to control the learning rate of your optimizer.
#       * The `adjust_augmentation` function should be called inside the validation loop and should be used to control how you do your data augmentations.
#        * The `check_early_stopping` should also be called during the validation loop and should be used to stop the training.
#   3. Modify your dataloader or use a custom collation function to filter data based on `underrepresented_classes.mode` and `underrepresented_classes.classes_to_ignore`.
#
#   4.  If mode == "weight" apply the `class_weights` by using a custom loss function.
#
#   5. If mode == "augment" use the `augmentation` parameter to modify the augmentation strength.